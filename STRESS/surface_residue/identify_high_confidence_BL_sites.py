import sys
import numpy as np
import os
import random
from operator import itemgetter, attrgetter, methodcaller
# import matplotlib.pyplot as plt
# import os.path

'''
Identifies the top BL sites using gap theory

            a) Reads in 1AHH__2.txt (generated by gap_theory_calculations.py), and identifies top sites based on criterion:
                        Reads in the top x%  of the delta_BL(i)/DELTA_BL values
                      ----> this reaches down to bl site "i"

            b) Goes into corresponding *.dat file, and reads down to site "i" = makes list "high_conf_BL_prev"

            c) Goes UP through list "high_conf_BL_prev", and for each site, determines jacc sim with all sites above. If the jacc sim w/any site above is greater than jac_thresh (set to 0.2?), then remove that below site from the candidate list of sites.

            d) The final list is the high-confidence list.

            e) For each protein -- make a corresponding file LISTING the top sites, as identified above.

example usage:

python identify_high_confidence_BL_sites.py     ../../../../../../out_ba_2DW7__BL.dat ../../../../2DW7__2.txt 0.005 0.01 0.33  2DW7 /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/
python identify_high_confidence_BL_sites.py ../../site__vs__freq_of_occurrence/input_files_annot/out_ba_2DW7__BL.dat 2DW7__2.txt 0.005 0.01 0.33 2DW7 /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/
python identify_high_confidence_BL_sites.py ../../site__vs__freq_of_occurrence/input_files_annot/out_ba_3ZWC__BL.dat 3ZWC__2.txt 0.005 0.01 0.33 3ZWC /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/
python identify_high_confidence_BL_sites.py ../../site__vs__freq_of_occurrence/input_files_annot/out_ba_4PIW__BL.dat 4PIW__2.txt 0.005 0.01 0.33 4PIW /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/
python identify_high_confidence_BL_sites.py ../../site__vs__freq_of_occurrence/input_files_annot/out_ba_1AHH__BL.dat 1AHH__2.txt 0.005 0.01 0.33 1AHH /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/
python identify_high_confidence_BL_sites.py ../../site__vs__freq_of_occurrence/input_files_annot/out_ba_1GD8__BL.dat 1GD8__2.txt 0.005 0.01 0.33 1GD8 /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/
python identify_high_confidence_BL_sites.py ../../site__vs__freq_of_occurrence/input_files_annot/out_ba_1URZ__BL.dat 1URZ__2.txt 0.005 0.01 0.33 1URZ /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/
python identify_high_confidence_BL_sites.py ../../site__vs__freq_of_occurrence/input_files_annot/out_ba_1UF8__BL.dat 1UF8__2.txt 0.005 0.01 0.33 1UF8 /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/
python identify_high_confidence_BL_sites.py ../../site__vs__freq_of_occurrence/input_files_annot/out_ba_1DZK__BL.dat 1DZK__2.txt 0.005 0.01 0.33 1DZK /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/
python identify_high_confidence_BL_sites.py ../../site__vs__freq_of_occurrence/input_files_annot/out_ba_3RPK__BL.dat 3RPK__2.txt 0.005 0.01 0.33 3RPK /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/
python identify_high_confidence_BL_sites.py ../../site__vs__freq_of_occurrence/input_files_annot/out_ba_1I0C__BL.dat 1I0C__2.txt 0.005 0.01 0.33 1I0C /Users/admin/Desktop/rsch/allostery/binding_leverage/chains_analyses/main_plots/est_BL_thresh/gap_theory_calculations/top_bl_sites/

'''


##  If the user did not enter the correct number of args, notify the user and terminate the program
if (len(sys.argv) != 7):
    print "\nYou provided " + str(len(sys.argv)-1) + " arguments even though 3 were expected!\n"
    sys.stderr.write("Usage: " + sys.argv[0] + " <binding_leverage_file> <x>\n")
    sys.stderr.write("where:\n")
    sys.stderr.write("   <*BL.dat file> is a *BL.dat file listing the processed binding sites, along w/their BL scores\n")
    sys.stderr.write("   <delta_bl file> is the output file generated from gap_theory_calculations.py (from STDIN) \n")
    sys.stderr.write("   <bl_delta_lines_cutoff> is a float indicating the fraction of the top lines to take in the delta_bl file file (usu set to 0.01) \n")
    sys.stderr.write("   <jacc_threshold> is used to identify similar lines\n")
    sys.stderr.write("   <jump_param> is a float representing thresh for distinguishing btwn JUMP and NO-JUMP CLASS distributions>\n")
    sys.stderr.write("   <PDB_ID> \n")
    sys.stderr.write("   <dir in which to print the top sites files> \n")
    sys.exit()

##  Assign input variables
binding_leverage_file = sys.argv[1]  ## the *BL.dat binding leverage output file listing all the candidate sites
binding_leverage_file_to_read = open(binding_leverage_file, "r")
delta_bl_file = sys.argv[2]
delta_bl_file_to_read = sys.stdin
bl_delta_lines_cutoff = float(sys.argv[2])
jacc_threshold = float(sys.argv[3])
jump_param = float(sys.argv[4])
pdb_id = sys.argv[5]
top_BL_sites_dir = sys.argv[6]
top_BL_sites_out = top_BL_sites_dir + pdb_id + "__SURFACE_CRITICAL_residues.dat"
top_BL_sites_out_to_write = open(top_BL_sites_out, "w")


BL_dat_lines = list()
for line in binding_leverage_file_to_read:
    BL_dat_lines.append(line)


delta_bl_lines = list()
delta_bl_tuples = list()
for line in delta_bl_file_to_read:
    ln_elems = list()
    ln_elems = line.split()
    if len(ln_elems) == 3:
        delta_bl_lines.append(line)
        tpl = list()
        rnd = ln_elems[0]
        tpl.append(rnd)
        bl_line_index = int(ln_elems[1])
        tpl.append(bl_line_index)
        delta_bl_vl = float(ln_elems[2])
        tpl.append(delta_bl_vl)
        delta_bl_tuples.append(tpl)

binding_leverage_file_to_read.close()
delta_bl_file_to_read.close()


##  Order the values in delta_bl_lines by descending values of their delta_bl(i) scores
sorted_1 = sorted(delta_bl_tuples, key=itemgetter(1))  ## first sort by delta_bl(i) value in DESCENDING order
#print "\n\n\nsrt" + str(sorted_1) + "\n\n\n\n\n"
sorted_2 = sorted(sorted_1, key=itemgetter(2), reverse=True)
#print "\n\n\nsrt2" + str(sorted_2) + "\n\n\n\n\n"


##  Determine whether or this delta_bl profile exhibits a "JUMP" or a "NO-JUMP" distribution. If it is a 
##  JUMP CLASS distribution, then disregard the top max_bl_lines_to_consider_pre which fall below the the jump
##  (and add to the max_bl_lines_to_consider_pre any  lines which lie above the jump). If this is a NO-JUMP
##  distribution, then just keep working w/all max_bl_lines_to_consider_pre f/above.
sorted_values = list()
i = 0
while i < len(sorted_2):
    sorted_values.append(float(sorted_2[i][2]))
    #print str(sorted_2[i][2])
    i += 1

large_jump_exists = "NO"
'''
index_of_jump = "NA"
i = 0
while i < len(sorted_values) - 1:
    ## At what point (if any) in the transversal down the list of sorted values is there a jump
    ## between line i and i-1 that is >= (1/3)rd the max sorted_value (ie, 1/3rd the entire range)
    jump = float((sorted_values[i] - sorted_values[i+1])) / float(sorted_values[0])
    if jump >= jump_param:
        large_jump_exists = "YES"
        index_of_jump = i
        break
    i += 1
'''


##  If NO JUMP exists -- then do not process max_bl_lines_to_consider_pre according to the jump criteria -- instead,
##  just consider the top max_bl_lines_to_consider_pre and remove replicate lines according to the jacc thresh (in 
##  next stop below).  If a JUMP DOES exist -- then process max_bl_lines_to_consider_pre accordingly:
bl_lines_to_consider_pre = list()
if large_jump_exists == "YES":   ## then take only the data BEFORE the jump
    i = 0
    while i <= index_of_jump:
        bl_lines_to_consider_pre.append(sorted_2[i][1])
        i += 1
else:   ##  then just identify the top BL lines based on bl_delta_lines_cutoff only 
    i = 0
    while i < (bl_delta_lines_cutoff * float(len(sorted_2))):
        #print str(sorted_2[i]) + "    " + str(sorted_2[i][1])
        bl_lines_to_consider_pre.append(sorted_2[i][1])
        i += 1
    #print "\n\n bl_lines_to_consider_pre:  " + str(bl_lines_to_consider_pre) + "\n"

if (len(bl_lines_to_consider_pre)) == 0:
	max_bl_lines_to_consider = 0
else:
	max_bl_lines_to_consider = max(bl_lines_to_consider_pre)

#print pdb_id + "\tindex_of_jump: " + str(index_of_jump) + "\tjump_val: " + str(jump)  + "\tmax_bl_lines_to_consider: " + str(max_bl_lines_to_consider)



i = 0
bl_line_index___2___jacc_status = {}
while i <= max_bl_lines_to_consider:
    bl_line_index___2___jacc_status[i] = "NON_REDUNDANT"
    i += 1


##  Remove the redundant lines (based on the jaccard threshold defined by user as command arg)
high_confidence_BL_sites = list()
i = max_bl_lines_to_consider
while i > 0:
    ##  If the current BL_dat_line is similar to any BL line above the current bl line, then the current bl line IS REDUNDANT
    ln_elems_a = list()
    ln_elems_a = BL_dat_lines[i].split()
    elems_a = list()
    elems_a = ln_elems_a[2:len(ln_elems_a)]
    elems_a_u = list(set(elems_a))
    j = i - 1
    while j >= 0:
        ##  Check the jacc score between line i and line j -- if it's high enough - then line i is redundant
        ln_elems_b = list()
        ln_elems_b = BL_dat_lines[j].split()
        elems_b = list()
        elems_b = ln_elems_b[2:len(ln_elems_b)]
        elems_b_u = list(set(elems_b))

        ## Get the union
        a__U__b = list()
        q = 0
        while q < len(elems_a_u):
            a__U__b.append(elems_a_u[q])
            q += 1
        q = 0
        while q < len(elems_b_u):
            a__U__b.append(elems_b_u[q])
            q += 1
        a__U__b__unq = list(set(a__U__b))

        ## Get the intersection
        a__A__b = list()
        for a in elems_a_u:
            if a in elems_b_u:
                a__A__b.append(a)

        ## Get the Jaccard similarity
        jaccard_similarity = float(len(a__A__b)) / float(len(a__U__b__unq))

        if jaccard_similarity >= jacc_threshold:
            bl_line_index___2___jacc_status[i] = "REDUNDANT_BTWN_" + str(i) + "_AND_" + str(j) +"___" + str(jaccard_similarity)

        j = j - 1
    i = i - 1



num_distinct_high_confidence_BL_sites = 0
i = 0
while i <= max_bl_lines_to_consider:
    #print str(i) + "    " + str(bl_line_index___2___jacc_status[i])
    if bl_line_index___2___jacc_status[i] == "NON_REDUNDANT":
        num_distinct_high_confidence_BL_sites += 1
        top_BL_sites_out_to_write.write(BL_dat_lines[i])
    i += 1

top_BL_sites_out_to_write.close()

print str(pdb_id) + "     num_distinct_high_confidence_BL_sites: " + str(num_distinct_high_confidence_BL_sites)


